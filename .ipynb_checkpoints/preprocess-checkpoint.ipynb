{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e556e491-f1a4-4532-b5d7-77c04dcf86ff",
   "metadata": {},
   "source": [
    "# ALL LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f1de20a-7b95-439b-9807-20f1c854bc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from fastai.tabular.all import df_shrink"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb15143-e11e-494f-a4d1-3d9fb2ddfa30",
   "metadata": {},
   "source": [
    "# GLOBAL FUNCTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703e20a5-e416-4006-b2ee-89f57d65f138",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## LOAD CONSTANT FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ceedf9d6-e791-4e42-99f7-19b08f91d561",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_constant(file):\n",
    "    t1 = time.time()\n",
    "    print(f\"==============================\")\n",
    "\n",
    "    print(f\"Loading file: {file}...\")\n",
    "    with open(f\"commons/{file}\", \"r\") as f:\n",
    "        features = json.load(f)\n",
    "\n",
    "    t2 = time.time()\n",
    "    print(f\"Finish... Total time: {t2 - t1} seconds\")\n",
    "    print(f\"==============================\")\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2dd227c-7b93-40c6-b533-55c1bea5028f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## PRE PROCESS FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67d056df-72ed-4fbd-a86e-a6bc34189129",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process(file, df):\n",
    "    t1 = time.time()\n",
    "    print(f\"==============================\")\n",
    "    print(f\"Processing file: {file}...\")\n",
    "    print(f\"\\tDimensions before process: {df.shape}\")\n",
    "    \n",
    "    print(f\"\\tStrip columns name...\")\n",
    "    df.columns = df.columns.str.strip()\n",
    "    \n",
    "    print(f\"\\tRename columns...\")\n",
    "    df.rename(columns=mapper_features, inplace=True)\n",
    "    \n",
    "    print(f\"\\tDrop columns...\")\n",
    "    df.drop(columns=drop_features, inplace=True)\n",
    "    \n",
    "    print(f\"\\tReplace 'infinity value' by 'nan'...\")\n",
    "    df.replace(to_replace=[np.inf, -np.inf], value=np.nan, inplace=True)\n",
    "    \n",
    "    print(f\"\\tDrop rows having 'nan' value...\")\n",
    "    print(f\"\\t...has been droping {df.isna().any(axis=1).sum()} rows\")\n",
    "    df.dropna(inplace=True)\n",
    "    \n",
    "    print(f\"\\tDrop duplicate rows...\")\n",
    "    print(f\"\\t...has been droping {df.duplicated().sum()} rows...\")\n",
    "    df.drop_duplicates(inplace=True)\n",
    "\n",
    "    print(f\"\\tReset index...\")\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "    print(f\"\\tShrink data-frame type...\")\n",
    "    df = df_shrink(df)\n",
    "    print(f\"\\tDimensions after process: {df.shape}\")\n",
    "\n",
    "    t2 = time.time()\n",
    "    print(f\"Finish... Total time: {t2 - t1} seconds\")\n",
    "    print(f\"==============================\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619cd03a-095c-4a8a-86e0-42d2428392da",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# PRE-PROCESSING..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1acfc08-c070-4e3b-946c-7b5fd9f789a8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## LOADING CONSTANT..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e903dfbb-74c0-4faf-9670-589d826c757d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "Loading file: mapper_for_training.json...\n",
      "Finish... Total time: 0.0020837783813476562 seconds\n",
      "==============================\n",
      "==============================\n",
      "Loading file: drop_for_training.json...\n",
      "Finish... Total time: 0.0010089874267578125 seconds\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "mapper_features = load_constant(\"mapper_for_training.json\")\n",
    "drop_features = load_constant(\"drop_for_training.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f88939-c143-43a9-9ee4-d53f785c1ab3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## READING DATASET..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56b8e2df-3a10-46dc-b192-43656fa969db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "Reading dataset...\n",
      "\tdataset\\DrDoS_DNS.csv\n",
      "\tdataset\\DrDoS_LDAP.csv\n",
      "\tdataset\\DrDoS_MSSQL.csv\n",
      "\tdataset\\DrDoS_NetBIOS.csv\n",
      "\tdataset\\DrDoS_NTP.csv\n",
      "\tdataset\\DrDoS_SNMP.csv\n",
      "\tdataset\\DrDoS_SSDP.csv\n",
      "\tdataset\\DrDoS_UDP.csv\n",
      "\tdataset\\Syn.csv\n",
      "\tdataset\\UDPLag.csv\n",
      "Finish... Total time: 0.0014524459838867188 seconds\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "print(f\"==============================\")\n",
    "\n",
    "print(f\"Reading dataset...\")\n",
    "files = glob.glob('dataset/*.csv')\n",
    "for file in files:\n",
    "    print(f\"\\t{file}\")\n",
    "\n",
    "t2 = time.time()\n",
    "print(f\"Finish... Total time: {t2 - t1} seconds\")\n",
    "print(f\"==============================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a61511-5768-4447-9c4b-b1ccc2b8c776",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## PROCESSING DATASET..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f4f2af5-c032-4b71-9f76-8725f1f1666f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "Processing dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_11900\\1366410201.py:6: DtypeWarning: Columns (85) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pre_process(file, pd.read_csv(file))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "Processing file: dataset\\DrDoS_DNS.csv...\n",
      "\tDimensions before process: (5074413, 88)\n",
      "\tStrip columns name...\n",
      "\tRename columns...\n",
      "\tDrop columns...\n",
      "\tReplace 'infinity value' by 'nan'...\n",
      "\tDrop rows having 'nan' value...\n",
      "\t...has been droping 0 rows\n",
      "\tDrop duplicate rows...\n",
      "\t...has been droping 4958216 rows...\n",
      "\tReset index...\n",
      "\tShrink data-frame type...\n",
      "\tDimensions after process: (116197, 22)\n",
      "Finish... Total time: 6.970324277877808 seconds\n",
      "==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_11900\\1366410201.py:6: DtypeWarning: Columns (85) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pre_process(file, pd.read_csv(file))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "Processing file: dataset\\DrDoS_LDAP.csv...\n",
      "\tDimensions before process: (2181542, 88)\n",
      "\tStrip columns name...\n",
      "\tRename columns...\n",
      "\tDrop columns...\n",
      "\tReplace 'infinity value' by 'nan'...\n",
      "\tDrop rows having 'nan' value...\n",
      "\t...has been droping 0 rows\n",
      "\tDrop duplicate rows...\n",
      "\t...has been droping 2150105 rows...\n",
      "\tReset index...\n",
      "\tShrink data-frame type...\n",
      "\tDimensions after process: (31437, 22)\n",
      "Finish... Total time: 2.9922029972076416 seconds\n",
      "==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_11900\\1366410201.py:6: DtypeWarning: Columns (85) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pre_process(file, pd.read_csv(file))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "Processing file: dataset\\DrDoS_MSSQL.csv...\n",
      "\tDimensions before process: (4524498, 88)\n",
      "\tStrip columns name...\n",
      "\tRename columns...\n",
      "\tDrop columns...\n",
      "\tReplace 'infinity value' by 'nan'...\n",
      "\tDrop rows having 'nan' value...\n",
      "\t...has been droping 0 rows\n",
      "\tDrop duplicate rows...\n",
      "\t...has been droping 4315964 rows...\n",
      "\tReset index...\n",
      "\tShrink data-frame type...\n",
      "\tDimensions after process: (208534, 22)\n",
      "Finish... Total time: 6.4344642162323 seconds\n",
      "==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_11900\\1366410201.py:6: DtypeWarning: Columns (85) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pre_process(file, pd.read_csv(file))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "Processing file: dataset\\DrDoS_NetBIOS.csv...\n",
      "\tDimensions before process: (4094986, 88)\n",
      "\tStrip columns name...\n",
      "\tRename columns...\n",
      "\tDrop columns...\n",
      "\tReplace 'infinity value' by 'nan'...\n",
      "\tDrop rows having 'nan' value...\n",
      "\t...has been droping 0 rows\n",
      "\tDrop duplicate rows...\n",
      "\t...has been droping 4073998 rows...\n",
      "\tReset index...\n",
      "\tShrink data-frame type...\n",
      "\tDimensions after process: (20988, 22)\n",
      "Finish... Total time: 5.282648324966431 seconds\n",
      "==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_11900\\1366410201.py:6: DtypeWarning: Columns (85) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pre_process(file, pd.read_csv(file))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "Processing file: dataset\\DrDoS_NTP.csv...\n",
      "\tDimensions before process: (1217007, 88)\n",
      "\tStrip columns name...\n",
      "\tRename columns...\n",
      "\tDrop columns...\n",
      "\tReplace 'infinity value' by 'nan'...\n",
      "\tDrop rows having 'nan' value...\n",
      "\t...has been droping 0 rows\n",
      "\tDrop duplicate rows...\n",
      "\t...has been droping 111793 rows...\n",
      "\tReset index...\n",
      "\tShrink data-frame type...\n",
      "\tDimensions after process: (1105214, 22)\n",
      "Finish... Total time: 3.7970619201660156 seconds\n",
      "==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_11900\\1366410201.py:6: DtypeWarning: Columns (85) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pre_process(file, pd.read_csv(file))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "Processing file: dataset\\DrDoS_SNMP.csv...\n",
      "\tDimensions before process: (5161377, 88)\n",
      "\tStrip columns name...\n",
      "\tRename columns...\n",
      "\tDrop columns...\n",
      "\tReplace 'infinity value' by 'nan'...\n",
      "\tDrop rows having 'nan' value...\n",
      "\t...has been droping 0 rows\n",
      "\tDrop duplicate rows...\n",
      "\t...has been droping 5047260 rows...\n",
      "\tReset index...\n",
      "\tShrink data-frame type...\n",
      "\tDimensions after process: (114117, 22)\n",
      "Finish... Total time: 6.923769235610962 seconds\n",
      "==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_11900\\1366410201.py:6: DtypeWarning: Columns (85) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pre_process(file, pd.read_csv(file))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "Processing file: dataset\\DrDoS_SSDP.csv...\n",
      "\tDimensions before process: (2611374, 88)\n",
      "\tStrip columns name...\n",
      "\tRename columns...\n",
      "\tDrop columns...\n",
      "\tReplace 'infinity value' by 'nan'...\n",
      "\tDrop rows having 'nan' value...\n",
      "\t...has been droping 0 rows\n",
      "\tDrop duplicate rows...\n",
      "\t...has been droping 1730687 rows...\n",
      "\tReset index...\n",
      "\tShrink data-frame type...\n",
      "\tDimensions after process: (880687, 22)\n",
      "Finish... Total time: 5.861386299133301 seconds\n",
      "==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_11900\\1366410201.py:6: DtypeWarning: Columns (85) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pre_process(file, pd.read_csv(file))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "Processing file: dataset\\DrDoS_UDP.csv...\n",
      "\tDimensions before process: (3136802, 88)\n",
      "\tStrip columns name...\n",
      "\tRename columns...\n",
      "\tDrop columns...\n",
      "\tReplace 'infinity value' by 'nan'...\n",
      "\tDrop rows having 'nan' value...\n",
      "\t...has been droping 0 rows\n",
      "\tDrop duplicate rows...\n",
      "\t...has been droping 2073713 rows...\n",
      "\tReset index...\n",
      "\tShrink data-frame type...\n",
      "\tDimensions after process: (1063089, 22)\n",
      "Finish... Total time: 6.993658542633057 seconds\n",
      "==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_11900\\1366410201.py:6: DtypeWarning: Columns (85) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pre_process(file, pd.read_csv(file))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "Processing file: dataset\\Syn.csv...\n",
      "\tDimensions before process: (1582681, 88)\n",
      "\tStrip columns name...\n",
      "\tRename columns...\n",
      "\tDrop columns...\n",
      "\tReplace 'infinity value' by 'nan'...\n",
      "\tDrop rows having 'nan' value...\n",
      "\t...has been droping 0 rows\n",
      "\tDrop duplicate rows...\n",
      "\t...has been droping 1427189 rows...\n",
      "\tReset index...\n",
      "\tShrink data-frame type...\n",
      "\tDimensions after process: (155492, 22)\n",
      "Finish... Total time: 2.6489596366882324 seconds\n",
      "==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_11900\\1366410201.py:6: DtypeWarning: Columns (85) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pre_process(file, pd.read_csv(file))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "Processing file: dataset\\UDPLag.csv...\n",
      "\tDimensions before process: (370166, 88)\n",
      "\tStrip columns name...\n",
      "\tRename columns...\n",
      "\tDrop columns...\n",
      "\tReplace 'infinity value' by 'nan'...\n",
      "\tDrop rows having 'nan' value...\n",
      "\t...has been droping 0 rows\n",
      "\tDrop duplicate rows...\n",
      "\t...has been droping 277761 rows...\n",
      "\tReset index...\n",
      "\tShrink data-frame type...\n",
      "\tDimensions after process: (92405, 22)\n",
      "Finish... Total time: 0.7242546081542969 seconds\n",
      "==============================\n",
      "Finish... Total time: 275.7635884284973 seconds\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "print(f\"==============================\")\n",
    "\n",
    "print(f\"Processing dataset...\")\n",
    "for file in files:\n",
    "    df = pre_process(file, pd.read_csv(file))\n",
    "    df.to_parquet(f\"dataset/{file.split('\\\\')[-1].replace('.csv', '.parquet')}\",engine=\"pyarrow\")\n",
    "\n",
    "t2 = time.time()\n",
    "print(f\"Finish... Total time: {t2 - t1} seconds\")\n",
    "print(f\"==============================\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
